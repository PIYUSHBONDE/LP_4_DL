{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d63e62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c125ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('LP-IV-datasets/CIFR(Ass2&3)/train_data.csv')\n",
    "test_data = pd.read_csv('LP-IV-datasets/CIFR(Ass2&3)/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e62de50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pixel_0', 'pixel_1', 'pixel_2', 'pixel_3', 'pixel_4', 'pixel_5',\n",
       "       'pixel_6', 'pixel_7', 'pixel_8', 'pixel_9',\n",
       "       ...\n",
       "       'pixel_3063', 'pixel_3064', 'pixel_3065', 'pixel_3066', 'pixel_3067',\n",
       "       'pixel_3068', 'pixel_3069', 'pixel_3070', 'pixel_3071', 'label'],\n",
       "      dtype='object', length=3073)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a8c6722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pixel_0', 'pixel_1', 'pixel_2', 'pixel_3', 'pixel_4', 'pixel_5',\n",
       "       'pixel_6', 'pixel_7', 'pixel_8', 'pixel_9',\n",
       "       ...\n",
       "       'pixel_3063', 'pixel_3064', 'pixel_3065', 'pixel_3066', 'pixel_3067',\n",
       "       'pixel_3068', 'pixel_3069', 'pixel_3070', 'pixel_3071', 'label'],\n",
       "      dtype='object', length=3073)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "842d3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop('label', axis=1).values\n",
    "y_train = train_data['label'].values\n",
    "\n",
    "X_test = test_data.drop('label', axis=1).values\n",
    "y_test = test_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c7f2a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape features to images (assuming images are 32x32)\n",
    "X_train = X_train.reshape(-1, 32, 32, 3)\n",
    "X_test = X_test.reshape(-1, 32, 32, 3)\n",
    "\n",
    "# # Normalize pixel values to between 0 and 1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b0d7514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train) \n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00114888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract features (pixels) and labels for training data\n",
    "# X = train_data.drop('label', axis=1).values\n",
    "# y = train_data['label'].values\n",
    "\n",
    "# # Reshape features to images (assuming images are 32x32)\n",
    "# X = X.reshape(-1, 32, 32, 3)\n",
    "\n",
    "# # Normalize pixel values to between 0 and 1\n",
    "# X = X / 255.0\n",
    "\n",
    "# # Split the training data into training and validation sets\n",
    "# X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7059e617",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# number of classes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# calculate total number of classes \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# for output layer\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of classes:\u001b[39m\u001b[38;5;124m\"\u001b[39m, K)\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "# number of classes\n",
    "K = len(set(y_train))\n",
    "# calculate total number of classes \n",
    "# for output layer\n",
    "print(\"number of classes:\", K)\n",
    "i = Input(shape=X_train[0].shape)\n",
    "# x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = MaxPooling2D((2, 2))(x)\n",
    " \n",
    "# x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = MaxPooling2D((2, 2))(x)\n",
    " \n",
    "# x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = MaxPooling2D((2, 2))(x)\n",
    " \n",
    "x = Flatten()(i)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "x = Dropout(0.2)(x)\n",
    " \n",
    "# Hidden layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    " \n",
    "# last hidden layer i.e.. output layer\n",
    "x = Dense(K, activation='softmax')(x)\n",
    " \n",
    "model = Model(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5125c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f88770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               393344    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 394634 (1.51 MB)\n",
      "Trainable params: 394634 (1.51 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8965 - accuracy: 0.3224 - val_loss: 1.7629 - val_accuracy: 0.3696\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7369 - accuracy: 0.3800 - val_loss: 1.6806 - val_accuracy: 0.4109\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6817 - accuracy: 0.4021 - val_loss: 1.6844 - val_accuracy: 0.3970\n",
      "Epoch 4/10\n",
      "1383/1563 [=========================>....] - ETA: 1s - loss: 1.6517 - accuracy: 0.4124"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('LP-IV-datasets/CIFR(Ass2&3)/train_data.csv')\n",
    "test_data = pd.read_csv('LP-IV-datasets/CIFR(Ass2&3)/test_data.csv')\n",
    "\n",
    "train_images = train_data.drop('label', axis=1).values\n",
    "train_labels = train_data['label'].values\n",
    "\n",
    "test_images = test_data.drop('label', axis=1).values\n",
    "test_labels = test_data['label'].values\n",
    "\n",
    "train_images = train_images.reshape((train_images.shape[0], 32, 32, 3))\n",
    "test_images = test_images.reshape((test_images.shape[0], 32, 32, 3))\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define the network architecture using Keras Sequential API\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(32, 32, 3)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the training data\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"\\nTest accuracy: {test_acc}\")\n",
    "\n",
    "# Plot training loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c5248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
